{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gdWi0BNXJS-6"
   },
   "source": [
    "# Redes Neurais Convolucionais com Tensorflow: Teoria e Prática\n",
    "## Introdução\n",
    "* Redes neurais convolucionais pertencem a uma categoria de algoritmos baseados em redes neurais artificiais que utilizam a convolução em pelo menos uma de suas camadas.\n",
    "* Tornaram - se o novo padrão em visão computacional.\n",
    "* Fáceis de treinar quando há grandes quantidades de amostras rotuladas.\n",
    "* Vantagens:\n",
    "  * Capacidade de extrair características relevantes através de aprendizado de transformações (kernels).\n",
    "  * Depender de menor número de parâmetros de ajustes do que redes totalmente conectadas com o mesmo número de camadas ocultas.\n",
    "* CNN's são formadas por sequências de camadas e cada uma destas possui uma função específica na propagação do sinal de entrada.\n",
    "  * Camadas Convolucionais: Responsáveis por extrair atributos dos volumes de entrada.\n",
    "  * Camadas de Pooling: Responsáveis por reduzir a dimensionalidade do volume resultante após as camadas convolucionais e ajudam a tornar a representação invariante a pequenas translações na entrada.\n",
    "  * Camadas Totalmente Conectadas: Responsáveis pela propagação do sinal por meio da multiplicação ponto a ponto e o uso de uma função de ativação.\n",
    "* A saída de uma CNN é a probabilidade da imagem de entrada pertencer a uma das classes para qual a rede foi treinada.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1D9ja2Y9RSF5"
   },
   "source": [
    "## Camada Convolucional\n",
    "* As camadas convolucionais consistem de um conjunto de filtros que recebem como entrada um arranjo 3D, também chamado de volume.\n",
    "* Um filtro possui dimensão reduzida, porém, se extende por toda a profundidade do volume de entrada.\n",
    "* Os filtros são ajustados para que seja ativados em presença de características relevantes identificadas no volume de entrada.\n",
    "* Operação de convolução: somatório do produto ponto a ponto entre os valores de um filtro e cada posição do volume de entrada.tpor uma função de ativação.\n",
    "* O volume resultante da camada é controlado por 3 prâmetros: profundidade (depth), passo (stride), e o zero-padding.\n",
    "  * Profundidade: Número de filtros utilizado.\n",
    "    * Cada filtro extrai idiferentes características.\n",
    "    * Quanto maior o número de filtros, maior o número de características extraídas, entretanto, a complexidade computacional também é maior.\n",
    "    * Portanto: > n° de filtros > n° de características > complexidade computacional\n",
    "   * Altura e largura do volume resultante dependem do passo e do zero-padding.\n",
    "   * Passo: Tamanho do salto na operação de convolução.\n",
    "      * Quanto maior o valor do passo, menor a altura e a largura do volume resultante, entretanto, características importantes podem ser perdidas.\n",
    "   * Zero-Padding: Operação que consiste em preencher com zeros a borda do volume de entrada.\n",
    "      * Vantagem: Permite controlar a altura e a largura do volume resultante e fazer com que fiquem com os mesmos valores do volume de entrada.\n",
    "    * Cálculos de Altura e Largura\n",
    "        * Altura:\n",
    "           * AC = [(A - F + 2P)/S] + 1 \n",
    "        * Largura\n",
    "            * LC = [(L - F + 2P)/S] + 1\n",
    "            \n",
    "                * A = Altura do volume de entrada\n",
    "                * L = Largura do volume de entrada\n",
    "                * S = Passo\n",
    "                * F = Tam. Filtro\n",
    "                * P = Valor Zero-Padding\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zlxugmgQPNC0"
   },
   "source": [
    "## Camada de Pooling \n",
    "* A camada de pooling tem como função reduzir progressivamente a dimensão espacial do volume de entrada.\n",
    "   * Redução do custo computacional da rede.\n",
    "   * Evita overfitting.\n",
    "* Valores pertencentes a uma determinada região do mapa de atributos, gerados pelas camadas convolucionais, são substituídos por alguma métrica dessa região.\n",
    "* A forma de pooling mais comum é a max pooling que consiste em substituir os valores de uma região por um valor máximo. \n",
    "* Cálculo de Altura e Largura dos valores resultantes:\n",
    "  * Altura\n",
    "    * AP = [(A - F)/S] + 1\n",
    "  * Largura\n",
    "    * LP = [(L - F)/S] + 1   \n",
    "  * A = Altura do volume de entrada\n",
    "  * L = Largura do volume de entrada\n",
    "  * S = Passo\n",
    "  * F = Tamanho da janela utilizada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cjnQbW_sW1-F"
   },
   "source": [
    "## Camada Totalmente Conectada\n",
    "* O objetivo das camadas totalmente conectadas é utilizar as características extraídas nas camadas convolucional e de pooling para classificar a imagem em uma classe pré-determinada.\n",
    "* Formadas por unidades de processamento conhecidas como neurônios.\n",
    "* Totalmente conectado significa que todos os neurônios da camada anterior estão conectados a todos da camada seguinte.\n",
    "* Matematicamente, um neurônio é: \n",
    "  * Somatório ponderado dos m sinais de entrada: cada sinal de entrada é multiplicado por um peso e é feito um somatório dos resultados.\n",
    "  * Resultado do somatório é somado a um valor chamado de bias que é responsável pelo deslocamento da função de ativação a qual essa soma é aplicada.\n",
    "* A última camada utiliza softmax como funçao de ativação.\n",
    "* Softmax recebe um vetor de valores como entrada e produz a distribuição probabilística da imagem pertencer a uma das classes na qual a rede foi treinada. Soma das probabilidades igual a 1.\n",
    "* Dropout: consiste em remover, aleatoriamente a cada iteração do treinamento, uma determinada porcentagem dos neurônios de uma camada, readicionando-os na iteração seguinte.\n",
    "  * Usada para reduzir o tempo de treino e evitar overfitting.\n",
    "  * Confere a rede a habilidade de aprender atributos mais robustos, já que um neurônio não pode depender da presença específica de outros neurônios.\n",
    "  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X7yuA4HMeFU4"
   },
   "source": [
    "## Treinando a Rede com o Backpropagation\n",
    "* Inicialmente, todos os filtros e pesos da rede são valores aleatórios.\n",
    "* Os valores iniciais são ajustados de forma a otimizar a acurácia considerando a base usada no treinamento.\n",
    "* A forma mais comum de treinamento é usando o algoritmo backpropagation.\n",
    "* Passo a passo backpropagation:\n",
    "  * Passo 1: Todos os filtros e pesos da rede são inicializados com valores aleatórios.\n",
    "  * Passo 2: A rede recebe uma imagem de treino como entrada e realiza o processo de propagação. Após o processo a rede obtém um valor de probabilidade para cada classe.\n",
    "  * Passo 3: É calculado o erro total obtido na camada de saída. Erro total é igual ao somatório do erro (probabilidade real - probabilidade obtida) de todas as classes. \n",
    "  * Passo 4: O algoritmo backpropagation é utilizado para calcular os valores dos gradientes de erro. A técnica do gradiente descendente é usada para ajustar valores dos filtros e pesos na proporção que eles contribuíram para o erro total.\n",
    "    * Com esses ajustes, o erro obtido a cada iteração é menor, o que significa que a rede está aprendendo a classificar corretamente as imagens.\n",
    "  * Passo 5: Repete os passos 2 - 4 para todas as imagens do conjunto de treinamento. \n",
    "* Época de treinamento: Processo que considera todas as imagens do conjunto de treinamento durante os passos 2 - 4.\n",
    "* O processo de treinamento da rede é repetido por consecutivas épocas até que: a média de erro obtida seja menor que um limiar ou que um número máximo de épocas seja atingido.\n",
    "* Quando uma das condições for atingida, a rede estará com os filtros e pesos calibrados para classificar o conjunto de treinamento. Dependendo da abundância e variedade do conjunto, a rede será capaz de generalizar bem com novas imagens não presentes no treinamento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YRnNkzr2l7ta"
   },
   "source": [
    "## Transferência de Aprendizado\n",
    "* Geralmente, um treinamento não é iniciado com valores aleatórios, pois, demanda muito tempo e recursos.\n",
    "* Utiliza-se então valores de pesos de uma rede já treinada para uma base muito grande.\n",
    "* Os pesos podem ser utilizados para inicializar e retreinar uma rede uma rede ou para extração de caracteres.\n",
    "* CNN como extrator de características\n",
    "  * Para utilizar um CNN já treinada como extrator de características, basta remover a última camada totalmente conectada da rede e utilizar a saída final da nova rede como características que descrevem a imagem de entrada.\n",
    "  * As características extraídas das imagens da nova base podem ser utilizadas juntamente com um classificador que requeira menos dados para o treinamento que uma CNN.\n",
    "    * Estratégia de extração de características é bastante utilizada para aplicação de imagens médicas.\n",
    "    * Também é comum em aplicações de recuperação de imagem baseada em conteúdo.\n",
    "* Fine-tunning uma CNN\n",
    "  * Consiste em dar continuidade ao treinamento de uma rede pretreinada utilizando o algoritmo backpropagation e uma nova base de imagens.\n",
    "  * Possível fazer com todas as camadas da rede ou somente com as duas últimas camadas.\n",
    "    * As primeiras camadas possuem extratores mais genéricos e as camadas mais profundas possuem detalhes mais específicos da base com a qual a rede foi originalmente treinada.\n",
    "   \n",
    "* Escolhendo a melhor técnica de transferência de aprendizado\n",
    "  * Dois principais fatores influenciam na escolha: o tamanho da nova base de imagens e a similaridade com a base original.\n",
    "  * Quatro cenários devem ser considerados na escolha da tecnica a ser usada:\n",
    "    * Nova base de imagens é pequena e similar a base original: o tamanho da base impossibilita o uso de fine-tunning, mas, como as bases são similiares, é possível usar a CNN pretreinada como extrator de características.\n",
    "    * Nova base de imagens é grande e similar a original: as duas técnicas obterão um bom resultado, mas, o fine-tunning oterá melhores resultados.\n",
    "    * Nova base de imagens é pequena e muito diferente da base original: utilizar a CNN pretreinada com extrator, entretanto, como as bases são muito diferentes, as camadas finais devem ser desconsideradas na extração.\n",
    "    * Nova base de imagens é grande e muito diferente da base original: a melhor opção é o fine-tunning de toda a CNN. Pois irá reduzir os tempos de treinamento de uma inicialização aleatória."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zMcv2kNB_6MO"
   },
   "source": [
    "## Códigos Fonte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lz3l9FA5ABv_"
   },
   "outputs": [],
   "source": [
    "#Pacotes principais\n",
    "import numpy as np\n",
    "from skimage.io import imread_collection\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CyhxiYNDAaNh"
   },
   "outputs": [],
   "source": [
    "''' weight_variable(shape)\n",
    "- A entrada dessa função é uma lista no formato [batch, altura, largura, \n",
    "profundidade], na qual batch representa o número de imagens processadas \n",
    "de uma vez. Altura, largura e profundidade representam as dimensões do \n",
    "volume de entrada.\n",
    "\n",
    "- O retorno dessa função são os valores de pesos inicializados de maneira\n",
    "aleatória seguindo uma distribuição normal com desvio padrão 0.1\n",
    "'''\n",
    "\n",
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "''' bias_variable(shape)\n",
    "- A entrada dessa função é o número de neurônios em casa camada.\n",
    "\n",
    "- O retorno dessa função são os valores de bias inicializados com 0.1.\n",
    "'''\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "''' conv2d(x, W)\n",
    "- A entrada dessa função pe o volume de entrada (x) e os pesos (W) da \n",
    "camada, ambos no formato [batch, altura, largura, profundidade]. Os \n",
    "pesos da camada são retornados na função weight_variable.\n",
    "\n",
    "- O retorno dessa função é o volume de saída da camada após a operação \n",
    "de convolução.\n",
    "\n",
    "- A variável strides = [1, 1, 1, 1] representa que o passo (stride) da\n",
    "convolução é igual a 1 em cada uma das dimensões\n",
    "\n",
    "- A variável padding='SAME' representa que a operação de zero padding\n",
    "será utilizada para que o volume de saída tenha a mesma dimensão do \n",
    "volume de entrada.\n",
    "'''\n",
    "\n",
    "def conv2d(x, W):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "''' max_pool_2x2(x)\n",
    "- A entrada dessa função é o volume de entrada (x) da camada de pooling no\n",
    "formato [batch, altura, largura, profundidade].\n",
    "\n",
    "- O retorno dessa função é o volume de saída da camada após a operação de \n",
    "max-pooling\n",
    "\n",
    "- A variável ksize = [1, 2, 2, 1] representa que o filtro utilizado na \n",
    "operação de pooling tem tamanho 2x2 na altura e na largura, e tamanho 1 na\n",
    "dimensão de batch e profundidade.\n",
    "\n",
    "- A variável strides = [1, 2, 2, 1] representa que o passo (stride) da \n",
    "operação de pooling é igual a 2 na altura e na largura, e 1 na dimensão de\n",
    "batch e profundidade.\n",
    "\n",
    "- A variável padding='SAME' representa que a operação de zero padding será\n",
    "utilizada para que o volume de saída tenha a dimensão igual a [batch, \n",
    "altura/2, largura/2, profundidade] do volume de entrada.\n",
    "'''\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], stride=[1, 2, 2, 1], \n",
    "                        padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4h6kNYFlIOM4"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-8b7649eeb959>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mvolume\u001b[0m \u001b[0mde\u001b[0m \u001b[0msa\u001b[0m\u001b[0;31mí\u001b[0m\u001b[0mda\u001b[0m \u001b[0mter\u001b[0m\u001b[0;31má\u001b[0m \u001b[0mdimens\u001b[0m\u001b[0;31mã\u001b[0m\u001b[0mo\u001b[0m \u001b[0migual\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m '''\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mW_conv1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweight_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m ''' A variável b_conv1 irá armazenar os valores de bias para os 32 filtros\n",
      "\u001b[1;31mNameError\u001b[0m: name 'batch' is not defined"
     ]
    }
   ],
   "source": [
    "''' A variável x irá armazenar as imagens de entrada da rede. Na lista com\n",
    "parâmetros [None, 3, 10000], o None é utilizado porque não sabemos a\n",
    "quantidade de imagens de entrada. O 3 representa que as imagens possuem 3\n",
    "canais. E o 10.000 representa a dimensão das imagens (100x100).\n",
    "'''\n",
    "x = tf.placeholder(tf.float32, [None, 3, 10000])\n",
    "\n",
    "''' A variável y_ representa as classes das imagens de entrada. Na lista \n",
    "com parâmetros [None, 2], o None é utilizado porque não sabemos a \n",
    "quantidade de imagens de entrada. O 2 representa a quantidade de classes \n",
    "que as imagens estão divididas. \n",
    "'''\n",
    "y_ = tf.placeholder(tf.float32, [None, 2])\n",
    "\n",
    "''' A função tf.reshape redimensiona a variável x para o formato de \n",
    "entrada que o Tensorflow aceita.\n",
    "'''\n",
    "x_image = tf.reshape(x, [-1, 100, 100, 3])\n",
    "\n",
    "''' A variável W_conv1 irá armazenar os pesos da primeira camada \n",
    "convolucional, que terá 32 filtros de tamanho 5x5 e profundidade 3. O \n",
    "volume de entrada dessa camada tem dimensão [batch, 100, 100, 32]. O\n",
    "volume de saída terá dimensão igual a [batch, 100, 100, 32]\n",
    "'''\n",
    "W_conv1 = weight_variable([batch, 100, 100, 32])\n",
    "\n",
    "''' A variável b_conv1 irá armazenar os valores de bias para os 32 filtros\n",
    "da primeira camada convolucional.\n",
    "'''\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "''' A função tf.nn.relu aplica a função de ativação Relu no volume de \n",
    "saída da primeira camada convolucional. A variável h_conv1 irá armazenar\n",
    "os valores resultantes da primeira camada convolucional.\n",
    "'''\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "\n",
    "''' A variável h_pool1 irá armazenar os valores resultantes após a \n",
    "operação de max-pool. O volume de entrada dessa camada tem dimensão\n",
    "[batch, 100, 100, 32]. O volume de saída será dimensão igual a [batch, \n",
    "100, 100, 32]\n",
    "'''\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "''' A variável W_conv2 irá armazenar os pesos da segunda camada \n",
    "convolucional, que terá 64 filtros de tamanho 5x5 e profundidade 32. O \n",
    "volume de entrada dessa camada tem dimensão [batch, 50, 50, 32]. O\n",
    "volume de saída terá dimensão igual a [batch, 50, 50, 64].\n",
    "'''\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "\n",
    "''' A variável b_conv2 irá armazenar os valores de bias para os 64 filtros\n",
    "da primeira camada convolucional.\n",
    "'''\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "''' A função tf.nn.relu aplica a função de ativação Relu no volume de \n",
    "saída da segunda camada convolucional. A variável h_conv2 irá armazenar\n",
    "os valores resultantes da primeira camada convolucional.\n",
    "'''\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "\n",
    "''' A variável h_pool2 irá armazenar os valores resultantes após a \n",
    "operação de max-pool. O volume de entrada dessa camada tem dimensão\n",
    "[batch, 50, 50, 64]. O volume de saída será dimensão igual a [batch, \n",
    "25, 25, 64].\n",
    "'''\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "''' A variável w_fc1 irá armazenar os pesos da primeira camada totalmente \n",
    "conectada. O volume de entrada dessa camada tem dimensão [batch, 25, 25, \n",
    "64]. Na lista com parâmetros [40000, 1024], o valor 40.000 é utilizado\n",
    "pois são 25*25*64 = 40.000 conexões. 1024 representa a quantidade de \n",
    "neurônios nessa camada.\n",
    "'''\n",
    "W_fc1 = weight_variable([40000, 1024])\n",
    "\n",
    "''' A variável b_fc1 irá armazenar os valores de bias para os 1024 fil\n",
    "tros da primeira camada totalmente conectada.\n",
    "'''\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "''' A função tf.reshape altera o formato de saída da segunda camada de\n",
    "pooling para o formato de entrada da primeira camada totalmente conectada.\n",
    "'''\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 40000])\n",
    "\n",
    "''' A função tf.nn.relu aplica a função de ativação Relu após a \n",
    "multiplicação ponto a ponto entre o volume de entrada e os pesos da \n",
    "primeira camada totalmente conectada.\n",
    "'''\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "''' A variável keep_prob conterá a porcentagem de neurônios que serão\n",
    "ativados na aplicação do \\textit{dropout} durante o treinamento.\n",
    "'''\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "'''A função tf.nn.dropout aplica o dropout no volume resultante após a \n",
    "primeira camada totalmente conectada.\n",
    "'''\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "'''A variável W_fc2 conterá os pesos da segunda camada totalmente \n",
    "conectada. O volume de entrada dessa camada tem 1024 valores, referentes \n",
    "a quantidade de neurônios da camada anterior. O segundo parâmetro com \n",
    "valor 2 representa as duas classes que a rede será treinada.'''\n",
    "W_fc2 = weight_variable([1024, 2])\n",
    "\n",
    "'''A variável b_fc2 conterá os valores de bias para os dois neurônios da \n",
    "segunda camada totalmente conectada.\n",
    "'''\n",
    "b_fc2 = bias_variable([2])\n",
    "\n",
    "'''A função tf.matmul realiza a multiplicação ponto a ponto entre o \n",
    "volume de entrada e os pesos da segunda camada \n",
    "totalmente conectada. y_conv é a variável que contém a estrutura da rede.\n",
    "'''\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pMIF5TdOIb2u"
   },
   "outputs": [],
   "source": [
    "'''A função softmax_cross_entropy_with_logits utiliza a função \n",
    "cross-entropy para calcular o erro entre a saída gerada pela CNN de uma \n",
    "determinada entrada e a sua classe correspondente.\n",
    "'''\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits\n",
    "                               (logits= y_conv, labels = y_))\n",
    "\n",
    "'''A função tf.train.AdamOptimizer atualiza os filtros e pesos da \n",
    "CNN utilizando o backpropagation. A variável train_step será utilizada \n",
    "para realizar o treinamento da rede.\n",
    "'''\n",
    "train_step = tf.train.AdamOptimizer(1e-5).minimize(cross_entropy)\n",
    "\n",
    "'''As duas próximas linhas são utilizadas para computar a predição da \n",
    "CNN e calcular a acurácia obtida.\n",
    "'''\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oNwBXJjlIidY"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'glob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-3608be57128b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mJá\u001b[0m \u001b[0ma\u001b[0m \u001b[0mvariável\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0mirá\u001b[0m \u001b[0mreceber\u001b[0m \u001b[0ma\u001b[0m \u001b[0mclasse\u001b[0m \u001b[0mde\u001b[0m \u001b[0mcada\u001b[0m \u001b[0muma\u001b[0m \u001b[0mdas\u001b[0m \u001b[0mimagens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m '''\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m '''A variável batch_size representa o número de imagens que serão \n",
      "\u001b[0;32m<ipython-input-4-3608be57128b>\u001b[0m in \u001b[0;36mread_images\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      3\u001b[0m classe de cada imagem.'''\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'*'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mim_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0msize_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'glob' is not defined"
     ]
    }
   ],
   "source": [
    "'''A função read_images recebe o endereço da pasta que contém a base de \n",
    "dados e retorna dois vetores, um contendo as imagens e o outro contendo a \n",
    "classe de cada imagem.'''\n",
    "def read_images(path):\n",
    "    classes = glob.glob(path+'*')\n",
    "    im_files = []\n",
    "    size_classes = []\n",
    "    for i in classes:\n",
    "        name_images_per_class = glob.glob(i+'/*')\n",
    "        im_files = im_files+name_images_per_class\n",
    "        size_classes.append(len(name_images_per_class))\n",
    "    labels = np.zeros((len(im_files),len(classes)))\n",
    "    \n",
    "    ant = 0\n",
    "    for id_i,i in enumerate(size_classes):\n",
    "        labels[ant:ant+i,id_i] = 1\n",
    "        ant = i\n",
    "    collection = imread_collection(im_files)\n",
    "    \n",
    "    data = []\n",
    "    for id_i,i in enumerate(collection):\n",
    "        data.append((i.reshape(3,-1)))\n",
    "    return np.asarray(data), np.asarray(labels)\n",
    "\n",
    "#A variável path contém o endereço da base de imagens\n",
    "path = '/Users/flavio/Desktop/cells_small/database/'\n",
    "\n",
    "'''A variável data irá receber as imagens presente na pasta especificada. \n",
    "Já a variável labels irá receber a classe de cada uma das imagens.\n",
    "'''\n",
    "data, labels = read_images(path)\n",
    "\n",
    "'''A variável batch_size representa o número de imagens que serão \n",
    "processadas a cada passo de treinamento.\n",
    "'''\n",
    "batch_size = 50\n",
    "\n",
    "'''A variável epochs representa o número de épocas de treinamento da rede.\n",
    "Uma época acontece quando todas as imagens do conjunto de treinamento \n",
    "passam pela rede e atualizam seus valores de pesos e filtros.\n",
    "'''\n",
    "epochs = 16\n",
    "\n",
    "'''A variável percent contém a porcentagem de imagens que serão \n",
    "utilizadas para o treinamento.\n",
    "'''\n",
    "percent = 0.5\n",
    "\n",
    "'''Os códigos das próximas 5 linhas estão apenas embaralhando a ordem\n",
    "das imagens e dos labels.\n",
    "'''\n",
    "data_size = len(data)\n",
    "idx = np.arange(data_size)\n",
    "random.shuffle(idx) \n",
    "data = data[idx]\n",
    "labels = labels[idx]\n",
    "\n",
    "'''Formando o conjunto de treinamento com a porcentagem de imagens \n",
    "especificado na variável percent.\n",
    "'''\n",
    "train = (data[0:np.int(data_size*percent),:,:],\n",
    "         labels[0:np.int(data_size*percent),:])\n",
    "\n",
    "'''Formando o conjunto de teste com as imagens que não foram \n",
    "utilizadas no treinamento.\n",
    "'''\n",
    "test = (data[np.int(data_size*(1-percent)):,:,:],\n",
    "        labels[np.int(data_size*(1-percent)):,:])\n",
    "\n",
    "#A variável train_size contém o tamanho do conjunto de treinamento.\n",
    "train_size = len(train[0])\n",
    "\n",
    "'''Até aqui apenas criamos as variáveis que irão realizar as operações do \n",
    "Tensorflow, porém é necessário criar uma sessão para que elas posam \n",
    "ser executadas.\n",
    "'''\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "#É necessário inicializar todas as variáveis\n",
    "tf.initialize_all_variables().run()\n",
    "\n",
    "'''Laço para repetir o processo de treinamento pelo número de épocas\n",
    "especificado.\n",
    "'''\n",
    "for n in range(epochs):\n",
    "    '''Laço para dividir o conjunto de treinamento em sub conjuntos com o \n",
    "    tamanho especificado na variável batch_size. Cada iteração \n",
    "    desse laço representa um batch.\n",
    "    '''\n",
    "    for i in range(int(np.ceil(train_size/batch_size))):\n",
    "        '''As próximas seis linhas de código dividem o conjunto de \n",
    "        treinamento nos batchs.\n",
    "        '''\n",
    "        if (i*batch_size+batch_size <= train_size):\n",
    "            batch = (train[0][i*batch_size:i*batch_size+batch_size],\n",
    "                     train[1][i*batch_size:i*batch_size+batch_size])\n",
    "        else:\n",
    "            batch = (train[0][i*batch_size:],\n",
    "                     train[1][i*batch_size:])\n",
    "            \n",
    "        '''Chamando a função de treinamento da rede com o valor de dropout\n",
    "        igual a 0.5.\n",
    "        '''\n",
    "        train_step.run(feed_dict={x: batch[0], y_: batch[1], \n",
    "        keep_prob: 0.5})\n",
    "        \n",
    "        '''Exibindo a acurácia obtida utilizando o conjunto de treinamento\n",
    "        a cada 5 iterações.\n",
    "        '''\n",
    "        if(n%5 == 0):\n",
    "            train_accuracy = accuracy.eval(feed_dict={x:batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "            print(\"Epoca %d, acuracia do treinamento = %g\"%(n, train_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XE6vlx2HIl5T"
   },
   "outputs": [],
   "source": [
    "'''Para computar a acurácia obtida pela CNN basta chamar a variável \n",
    "accuracy criada anteriormente, e epecificarmos as imagens de entrada e \n",
    "as classes correspondentes. A variável keep_prob que representa o\n",
    "dropout recebe o valor 1, pois essa operação é utilizada somente no \n",
    "treinamento\n",
    "'''\n",
    "acuracia = accuracy.eval(feed_dict={x: test[0][:], y_: test[1][:], keep_prob: 1.0})\n",
    "print(\"Acuracia = \", acuracia)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Tutorial Redes Neurais.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
